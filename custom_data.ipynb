{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pickle\n",
    "from utils import *\n",
    "from metrics import *\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:48<00:00,  1.22it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]/home/chri6578/Documents/CES/utils.py:465: RuntimeWarning: Mean of empty slice\n",
      "  mean_effect = np.nanmean(effect)\n",
      "  0%|          | 0/59 [24:45:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(E_all\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      8\u001b[0m tau_bar \u001b[38;5;241m=\u001b[39m bar_tau_0\n\u001b[0;32m---> 10\u001b[0m A_est \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mE_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# acc = accuracy(A_est, Gamma, n)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# sgn_acc = sign_accuracy(A_est, Gamma)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# cannot run for large n. too slow (need to speed up)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CES/utils.py:461\u001b[0m, in \u001b[0;36mestimate_\u001b[0;34m(E_all, tau_bar, n)\u001b[0m\n\u001b[1;32m    418\u001b[0m     print(c, len(C))\n\u001b[1;32m    419\u001b[0m     return A_est \n\u001b[1;32m    421\u001b[0m # Idea: The search_ operation can be performed once and saved as a dictionary (per node)\n\u001b[1;32m    422\u001b[0m \n\u001b[1;32m    423\u001b[0m # import numpy as np\n\u001b[1;32m    424\u001b[0m # from collections import defaultdict\n\u001b[1;32m    425\u001b[0m # from tqdm import tqdm\n\u001b[1;32m    426\u001b[0m \n\u001b[1;32m    427\u001b[0m # def search_(E_all, tau_bar, n, k, T_all_set):\n\u001b[1;32m    428\u001b[0m #     \"\"\" Optimized search function with set lookup for faster performance. \"\"\"\n\u001b[1;32m    429\u001b[0m #     binary_array = np.unpackbits(np.array([k], dtype=np.uint8).view(np.uint8), bitorder='big')[-n:]\n\u001b[1;32m    430\u001b[0m     \n\u001b[1;32m    431\u001b[0m #     for t in T_all_set:\n\u001b[1;32m    432\u001b[0m #         z = np.zeros(n, dtype=np.int8)\n\u001b[1;32m    433\u001b[0m #         for j in range(n):\n\u001b[1;32m    434\u001b[0m #             z[j] = np.any((E_all[j] > t - tau_bar) & (E_all[j] < t))\n\u001b[1;32m    435\u001b[0m         \n\u001b[1;32m    436\u001b[0m #         if np.array_equal(binary_array, z):\n\u001b[1;32m    437\u001b[0m #             return True\n\u001b[1;32m    438\u001b[0m #     return False\n\u001b[1;32m    439\u001b[0m \n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m # def estimate_(E_all, tau_bar, n):\n\u001b[1;32m    442\u001b[0m #     pow2 = 1 << np.arange(n)  # Faster than 2**np.arange(n)\n\u001b[1;32m    443\u001b[0m     \n\u001b[1;32m    444\u001b[0m #     Y1 = [defaultdict(int) for _ in range(n)]\n\u001b[1;32m    445\u001b[0m     \n\u001b[1;32m    446\u001b[0m #     # Precompute T_all as a set for fast lookup\n\u001b[1;32m    447\u001b[0m #     T_all_set = {t for sublist in E_all.values() for t in sublist}\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m #     for i in tqdm(range(n)):\n\u001b[1;32m    450\u001b[0m #         for t in E_all[i]:\n\u001b[1;32m    451\u001b[0m #             z = np.zeros(n, dtype=np.int8)\n\u001b[1;32m    452\u001b[0m #             for j in range(n):\n\u001b[1;32m    453\u001b[0m #                 z[j] = np.any((E_all[j] > t - tau_bar) & (E_all[j] < t))\n\u001b[1;32m    454\u001b[0m             \n\u001b[1;32m    455\u001b[0m #             Y1[i][np.dot(z, pow2)] = 1\n\u001b[1;32m    456\u001b[0m \n\u001b[1;32m    457\u001b[0m #     # Estimate adjacency matrix\n\u001b[1;32m    458\u001b[0m #     A_est = np.zeros((n, n))\n\u001b[1;32m    459\u001b[0m \n\u001b[1;32m    460\u001b[0m #     for i in tqdm(range(n)):\n\u001b[0;32m--> 461\u001b[0m #         for j in range(n):\n\u001b[1;32m    462\u001b[0m #             effect = []\n\u001b[1;32m    463\u001b[0m #             keys_list = list(Y1[i].keys())\n\u001b[1;32m    464\u001b[0m             \n\u001b[1;32m    465\u001b[0m #             for k in keys_list:\n\u001b[1;32m    466\u001b[0m #                 if not (k & (1 << j)):  # If bit j is not set\n\u001b[1;32m    467\u001b[0m                     \n\u001b[1;32m    468\u001b[0m #                     k_j = k + pow2[j]  # Set bit j\n\u001b[1;32m    469\u001b[0m #                     if search_(E_all, tau_bar, n, k_j, T_all_set) and search_(E_all, tau_bar, n, k, T_all_set):\n\u001b[1;32m    470\u001b[0m                         \n\u001b[1;32m    471\u001b[0m #                         effect.append(Y1[i].get(k_j, 0) - Y1[i].get(k, 0))\n\u001b[1;32m    472\u001b[0m             \n\u001b[1;32m    473\u001b[0m #             mean_effect = np.nanmean(effect)\n\u001b[1;32m    474\u001b[0m #             if not np.isnan(mean_effect):\n\u001b[1;32m    475\u001b[0m #                 A_est[i, j] = mean_effect\n\u001b[1;32m    476\u001b[0m \n\u001b[1;32m    477\u001b[0m #     return A_est\n",
      "File \u001b[0;32m~/Documents/CES/utils.py:426\u001b[0m, in \u001b[0;36msearch_\u001b[0;34m(E_all, tau_bar, n, k, T_all_set)\u001b[0m\n\u001b[1;32m    418\u001b[0m     print(c, len(C))\n\u001b[1;32m    419\u001b[0m     return A_est \n\u001b[1;32m    421\u001b[0m # Idea: The search_ operation can be performed once and saved as a dictionary (per node)\n\u001b[1;32m    422\u001b[0m \n\u001b[1;32m    423\u001b[0m # import numpy as np\n\u001b[1;32m    424\u001b[0m # from collections import defaultdict\n\u001b[1;32m    425\u001b[0m # from tqdm import tqdm\n\u001b[0;32m--> 426\u001b[0m \n\u001b[1;32m    427\u001b[0m # def search_(E_all, tau_bar, n, k, T_all_set):\n\u001b[1;32m    428\u001b[0m #     \"\"\" Optimized search function with set lookup for faster performance. \"\"\"\n\u001b[1;32m    429\u001b[0m #     binary_array = np.unpackbits(np.array([k], dtype=np.uint8).view(np.uint8), bitorder='big')[-n:]\n\u001b[1;32m    430\u001b[0m     \n\u001b[1;32m    431\u001b[0m #     for t in T_all_set:\n\u001b[1;32m    432\u001b[0m #         z = np.zeros(n, dtype=np.int8)\n\u001b[1;32m    433\u001b[0m #         for j in range(n):\n\u001b[1;32m    434\u001b[0m #             z[j] = np.any((E_all[j] > t - tau_bar) & (E_all[j] < t))\n\u001b[1;32m    435\u001b[0m         \n\u001b[1;32m    436\u001b[0m #         if np.array_equal(binary_array, z):\n\u001b[1;32m    437\u001b[0m #             return True\n\u001b[1;32m    438\u001b[0m #     return False\n\u001b[1;32m    439\u001b[0m \n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m # def estimate_(E_all, tau_bar, n):\n\u001b[1;32m    442\u001b[0m #     pow2 = 1 << np.arange(n)  # Faster than 2**np.arange(n)\n\u001b[1;32m    443\u001b[0m     \n\u001b[1;32m    444\u001b[0m #     Y1 = [defaultdict(int) for _ in range(n)]\n\u001b[1;32m    445\u001b[0m     \n\u001b[1;32m    446\u001b[0m #     # Precompute T_all as a set for fast lookup\n\u001b[1;32m    447\u001b[0m #     T_all_set = {t for sublist in E_all.values() for t in sublist}\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m #     for i in tqdm(range(n)):\n\u001b[1;32m    450\u001b[0m #         for t in E_all[i]:\n\u001b[1;32m    451\u001b[0m #             z = np.zeros(n, dtype=np.int8)\n\u001b[1;32m    452\u001b[0m #             for j in range(n):\n\u001b[1;32m    453\u001b[0m #                 z[j] = np.any((E_all[j] > t - tau_bar) & (E_all[j] < t))\n\u001b[1;32m    454\u001b[0m             \n\u001b[1;32m    455\u001b[0m #             Y1[i][np.dot(z, pow2)] = 1\n\u001b[1;32m    456\u001b[0m \n\u001b[1;32m    457\u001b[0m #     # Estimate adjacency matrix\n\u001b[1;32m    458\u001b[0m #     A_est = np.zeros((n, n))\n\u001b[1;32m    459\u001b[0m \n\u001b[1;32m    460\u001b[0m #     for i in tqdm(range(n)):\n\u001b[1;32m    461\u001b[0m #         for j in range(n):\n\u001b[1;32m    462\u001b[0m #             effect = []\n\u001b[1;32m    463\u001b[0m #             keys_list = list(Y1[i].keys())\n\u001b[1;32m    464\u001b[0m             \n\u001b[1;32m    465\u001b[0m #             for k in keys_list:\n\u001b[1;32m    466\u001b[0m #                 if not (k & (1 << j)):  # If bit j is not set\n\u001b[1;32m    467\u001b[0m                     \n\u001b[1;32m    468\u001b[0m #                     k_j = k + pow2[j]  # Set bit j\n\u001b[1;32m    469\u001b[0m #                     if search_(E_all, tau_bar, n, k_j, T_all_set) and search_(E_all, tau_bar, n, k, T_all_set):\n\u001b[1;32m    470\u001b[0m                         \n\u001b[1;32m    471\u001b[0m #                         effect.append(Y1[i].get(k_j, 0) - Y1[i].get(k, 0))\n\u001b[1;32m    472\u001b[0m             \n\u001b[1;32m    473\u001b[0m #             mean_effect = np.nanmean(effect)\n\u001b[1;32m    474\u001b[0m #             if not np.isnan(mean_effect):\n\u001b[1;32m    475\u001b[0m #                 A_est[i, j] = mean_effect\n\u001b[1;32m    476\u001b[0m \n\u001b[1;32m    477\u001b[0m #     return A_est\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36many\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bar_tau_0 = 20\n",
    "\n",
    "with open(\"/home/chri6578/Documents/causaldata/NAH/alarms.pkl\", \"rb\") as file:\n",
    "    E_all = pickle.load(file)\n",
    "\n",
    "n = len(E_all.keys())\n",
    "\n",
    "tau_bar = bar_tau_0\n",
    "\n",
    "A_est = estimate_(E_all, tau_bar, n )\n",
    "\n",
    "# acc = accuracy(A_est, Gamma, n)\n",
    "# sgn_acc = sign_accuracy(A_est, Gamma)\n",
    "\n",
    "# print(f'{trial}, {p_0}, {n}, {Sn}, {tau_diff}, {acc}, {sgn_acc}')\n",
    "\n",
    "\n",
    "# cannot run for large n. too slow (need to speed up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
